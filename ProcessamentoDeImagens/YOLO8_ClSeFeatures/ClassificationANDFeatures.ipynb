{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1cd949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import shutil\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9057eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Path('E:/HandsOnPython/Datasets/dataset2')\n",
    "root = Path('E:\\HandsOnPython\\Datasets\\YOLO_CLS_WEATHER')\n",
    "Path(root/'weather'/'train'/'rain').mkdir(parents=True, exist_ok=True)\n",
    "Path(root/'weather'/'train'/'sunrise').mkdir(parents=True, exist_ok=True)\n",
    "Path(root/'weather'/'train'/'shine').mkdir(parents=True, exist_ok=True)\n",
    "Path(root/'weather'/'train'/'cloudy').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "Path(root/'weather'/'val'/'rain').mkdir(parents=True, exist_ok=True)\n",
    "Path(root/'weather'/'val'/'sunrise').mkdir(parents=True, exist_ok=True)\n",
    "Path(root/'weather'/'val'/'shine').mkdir(parents=True, exist_ok=True)\n",
    "Path(root/'weather'/'val'/'cloudy').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "Path(root/'weatherSplit').mkdir(parents=True, exist_ok=True)\n",
    "Path(root/'weatherSplit'/'rain').mkdir(parents=True, exist_ok=True)\n",
    "Path(root/'weatherSplit'/'sunrise').mkdir(parents=True, exist_ok=True)\n",
    "Path(root/'weatherSplit'/'shine').mkdir(parents=True, exist_ok=True)\n",
    "Path(root/'weatherSplit'/'cloudy').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbd7d0e",
   "metadata": {},
   "source": [
    "Separando as classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663ce7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img in dataset.rglob('*'):\n",
    "   \n",
    "#     name = img.name.split('.')[0]\n",
    "\n",
    "#     if('cloudy' in name):\n",
    "#         shutil.copy(img,Path().resolve()/'weatherSplit'/'cloudy')\n",
    "#         continue\n",
    "\n",
    "#     if('rain' in name):\n",
    "#         shutil.copy(img,Path().resolve()/'weatherSplit'/'rain')\n",
    "#         continue\n",
    "\n",
    "#     if('shine' in name):\n",
    "#         shutil.copy(img,Path().resolve()/'weatherSplit'/'shine')\n",
    "#         continue\n",
    "\n",
    "#     if('sunrise' in name):\n",
    "#         shutil.copy(img,Path().resolve()/'weatherSplit'/'sunrise')\n",
    "#         continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1456bfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain = list((Path().resolve()/'weatherSplit'/'rain').rglob('*'))\n",
    "sunrise = list((Path().resolve()/'weatherSplit'/'sunrise').rglob('*'))\n",
    "shine = list((Path().resolve()/'weatherSplit'/'shine').rglob('*'))\n",
    "cloudy = list((Path().resolve()/'weatherSplit'/'cloudy').rglob('*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ac6737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "climas = {\n",
    "    'rain': rain,\n",
    "    'shine': shine,\n",
    "    'sunrise': sunrise,\n",
    "    'cloudy':cloudy\n",
    "}\n",
    "\n",
    "for key, value in climas.items():\n",
    "    \n",
    "    tamanho = len(value)\n",
    "    idx_shuffle = np.random.permutation(tamanho)\n",
    "    corte = tamanho//5 #20% dos dados\n",
    "    \n",
    "    val = idx_shuffle[:corte]\n",
    "    train = idx_shuffle[corte:]\n",
    "\n",
    "    for idx in val:\n",
    "        shutil.copy(value[idx], Path().resolve()/'weather'/'val'/key)\n",
    "\n",
    "    for idx in train:\n",
    "        shutil.copy(value[idx], Path().resolve()/'weather'/'train'/key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28789bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\HandsOnPython\\Capitulo 1 - Preço de Casas\\ProcessamentoDeImagens\\yoloenv\\lib\\site-packages\\ultralytics\\nn\\tasks.py:336: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolov8n-cls.pt\")  # load a pretrained model (recommended for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a955141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.58  Python-3.10.0 torch-2.5.0+cpu CPU\n",
      "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=E:\\HandsOnPython\\Capitulo 1 - Preo de Casas\\ProcessamentoDeImagens\\YOLO8_ClSeFeatures\\weather, epochs=1, patience=50, batch=16, imgsz=64, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs\\classify\\train3\n",
      "Overriding model.yaml nc=1000 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    335364  ultralytics.nn.modules.Classify              [256, 4]                      \n",
      "YOLOv8n-cls summary: 99 layers, 1443412 parameters, 1443412 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "e:\\HandsOnPython\\Capitulo 1 - Preço de Casas\\ProcessamentoDeImagens\\yoloenv\\lib\\site-packages\\ultralytics\\yolo\\engine\\trainer.py:217: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias\n",
      "Image sizes 64 train, 64 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\train3\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mE:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mHandsOnPython\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mCapitulo 1 - Preço de Casas\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mProcessamentoDeImagens\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mYOLO8_ClSeFeatures\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mweather\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\HandsOnPython\\Capitulo 1 - Preço de Casas\\ProcessamentoDeImagens\\yoloenv\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py:329\u001b[0m, in \u001b[0;36mYOLO.train\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# update model and cfg after training\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[1;32me:\\HandsOnPython\\Capitulo 1 - Preço de Casas\\ProcessamentoDeImagens\\yoloenv\\lib\\site-packages\\ultralytics\\yolo\\engine\\trainer.py:191\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    189\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\HandsOnPython\\Capitulo 1 - Preço de Casas\\ProcessamentoDeImagens\\yoloenv\\lib\\site-packages\\ultralytics\\yolo\\engine\\trainer.py:302\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 302\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_train_batch_start\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;66;03m# Warmup\u001b[39;00m\n",
      "File \u001b[1;32me:\\HandsOnPython\\Capitulo 1 - Preço de Casas\\ProcessamentoDeImagens\\yoloenv\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32me:\\HandsOnPython\\Capitulo 1 - Preço de Casas\\ProcessamentoDeImagens\\yoloenv\\lib\\site-packages\\ultralytics\\yolo\\data\\build.py:39\u001b[0m, in \u001b[0;36mInfiniteDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[1;32m---> 39\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\HandsOnPython\\Capitulo 1 - Preço de Casas\\ProcessamentoDeImagens\\yoloenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32me:\\HandsOnPython\\Capitulo 1 - Preço de Casas\\ProcessamentoDeImagens\\yoloenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32me:\\HandsOnPython\\Capitulo 1 - Preço de Casas\\ProcessamentoDeImagens\\yoloenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32me:\\HandsOnPython\\Capitulo 1 - Preço de Casas\\ProcessamentoDeImagens\\yoloenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32me:\\HandsOnPython\\Capitulo 1 - Preço de Casas\\ProcessamentoDeImagens\\yoloenv\\lib\\site-packages\\ultralytics\\yolo\\data\\dataset.py:252\u001b[0m, in \u001b[0;36mClassificationDataset.__getitem__\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    250\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malbum_transforms(image\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mcvtColor(im, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 252\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch_transforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m'\u001b[39m: sample, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m'\u001b[39m: j}\n",
      "File \u001b[1;32me:\\HandsOnPython\\Capitulo 1 - Preço de Casas\\ProcessamentoDeImagens\\yoloenv\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32me:\\HandsOnPython\\Capitulo 1 - Preço de Casas\\ProcessamentoDeImagens\\yoloenv\\lib\\site-packages\\ultralytics\\yolo\\data\\augment.py:764\u001b[0m, in \u001b[0;36mCenterCrop.__call__\u001b[1;34m(self, im)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, im):  \u001b[38;5;66;03m# im = np.array HWC\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     imh, imw \u001b[38;5;241m=\u001b[39m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    765\u001b[0m     m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(imh, imw)  \u001b[38;5;66;03m# min dimension\u001b[39;00m\n\u001b[0;32m    766\u001b[0m     top, left \u001b[38;5;241m=\u001b[39m (imh \u001b[38;5;241m-\u001b[39m m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, (imw \u001b[38;5;241m-\u001b[39m m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "model.train(data=, epochs=1, imgsz=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b4e6134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for pasta in [\"rain\", \"shine\", \"sunrise\", \"cloudy\", \"train\", \"val\"]:\n",
    "    shutil.rmtree(pasta, ignore_errors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b32a6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python310_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
