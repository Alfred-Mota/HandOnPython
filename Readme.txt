A biblioteca sklearn espera matrizes para a variavel X: [[1],[2],[3],[4]], para a biblioteca cada linha √© uma amostra e cada coluna
√© uma feature (caracteristica). No caso de arrays 1D, nao √© possivel saber se sao 1 amostra e varias features ou se sao varias amostras com 
somente uma feature

X = [
    [1,1.5,1.8],
    [2,2.5,2.8],
    [3,3.5,3.8],
    [4,4.5,4.8],
    [5,5.5,5.8],
]

    RESUMO CAPITULO 2

üîπ M√©todos

    ‚Ä¢fit() ‚Üí Aprende com os dados (ajusta o modelo).
    Exemplo: calcula m√©dia, desvio padr√£o, m√°ximos e m√≠nimos no caso de normaliza√ß√£o, ou ajusta coeficientes no caso de regress√£o.

    ‚Ä¢transform() ‚Üí Aplica uma transforma√ß√£o nos dados j√° ‚Äúaprendida‚Äù pelo fit() (ex: normaliza√ß√£o, codifica√ß√£o, etc.).
    Exemplo: StandardScaler, OneHotEncoder.

    ‚Ä¢fit_transform() ‚Üí Combina fit e transform (ajusta e transforma ao mesmo tempo, √∫til no pr√©-processamento).

    ‚Ä¢predict() ‚Üí Realiza previs√µes com base no modelo treinado.

    ‚Ä¢Pipelines (sklearn.pipeline.Pipeline) ‚Üí
    Permitem encadear v√°rias etapas (pr√©-processamento + modelo) em uma √∫nica estrutura, garantindo que tudo ocorra na ordem
    correta durante o treino e teste.
    Eexemplo:
            model = make_pipeline(poly, std_scaler, reg_linear)
            model.fit(X,y)
            O pipeline funciona da seguinte forma, ao chamar o .fit() em cada etapa dos pipelines √© chamado o metodo fit_transform exceto no
            ultimo metodo no qual √© chamado apenas fit()

Apenas os transformadores possuem os metodos transform. Metodos preditivos possuem predict, score e fit

‚öôÔ∏è Pr√©-processamento (sklearn.preprocessing)

    ‚Ä¢OneHotEncoder ‚Üí Lida com vari√°veis categ√≥ricas, convertendo-as em vetores bin√°rios (0 e 1).
    Exemplo: "vermelho", "verde", "azul" ‚Üí [1,0,0], [0,1,0], [0,0,1].

    ‚Ä¢StandardScaler ‚Üí Normaliza os dados com base na m√©dia e desvio padr√£o.
    ‚ö†Ô∏è Sens√≠vel a outliers.

    ‚Ä¢MinMaxScaler ‚Üí Redimensiona os dados para um intervalo definido (geralmente entre 0 e 1).
    Menos sens√≠vel a outliers que o StandardScaler.

    SimpleImputer: vem do sklearn.impute, metodo utilizado para tratar valores NAN

M√©tricas (sklearn.metrics)

Usadas para avaliar o desempenho de modelos.

    ‚Ä¢mean_squared_error (MSE) ‚Üí mede o erro quadr√°tico m√©dio.

    ‚Ä¢root_mean_squared_error (RMSE) ‚Üí raiz quadrada do MSE (mesma unidade da vari√°vel de sa√≠da).

    ‚Ä¢r2_score ‚Üí mede o qu√£o bem o modelo explica a variabilidade dos dados.

    ‚Ä¢mean_absolute_error (MAE) ‚Üí m√©dia dos erros absolutos (menos sens√≠vel a outliers que o MSE).

    ‚Ä¢precision_score, recall_score, f1_score, precision_recall_curve

ü§ñ Modelos

    ‚Ä¢from sklearn.linear_model import LinearRegression
    Modelo de regress√£o linear ‚Äî √∫til quando h√° uma rela√ß√£o linear entre as vari√°veis.
    Suporta regress√£o m√∫ltipla (v√°rios par√¢metros).

    ‚Ä¢from sklearn.tree import DecisionTreeRegressor, plot_tree
    Modelo de √°rvore de decis√£o ‚Äî divide os dados em ramos baseados em regras simples.
    plot_tree() ‚Üí visualiza a estrutura da √°rvore.

    ‚Ä¢from sklearn.model_selection import cross_val_score
    Realiza valida√ß√£o cruzada, testando o modelo em diferentes parti√ß√µes dos dados para medir desempenho de forma mais confi√°vel.

    ‚Ä¢from sklearn.ensemble import RandomForestRegressor
    Modelo de floresta aleat√≥ria, combina v√°rias √°rvores de decis√£o com diferentes amostras e par√¢metros.
    Mais robusto, por√©m mais pesado computacionalmente.


### Capitulo 3

‚Ä¢ Analise de imagens de numeros com 700 pixels, e foram dividos em matrizes de 28x28

‚Ä¢ O estudo se iniciou tentando detectar numeros 5, porem devido ao desbalanceamento gerou-se um modelo pouco confiavel, que aprendeu a detectar valores diferentes de 5. 

‚Ä¢ sklearn.datasets √© um utilitario para buscar datasets

‚Ä¢ SGDClassifier: metodo de classifica√ß√£o aleatoria em lotes, util para analises de altas dimensoes. Mais impreciso que metodos 
diretos, como Regressao Linear, porem √© mais rapido.

‚Ä¢ Metricas de classifica√ß√£o:
    - Acuracia: Acertos em rela√ß√£o ao total de amostras (Verdadeiros Positivos), ou seja, acertos sao falar que 1 n√£o √© 5 e que 5 √© 5
    - Precis√£o: Entre os Verdadeiros Positivos e Falsos Positivos, qual a taxa de Verdadeiros Positivos. Entre oque passou, o quanto esta correto ?
    - Recall: Entre os Verdadeiros Positivos e Falsos Negativos, qual a taxa de filtragem de Verdadeiros Positivos. Entre todos os positivos, acertou quanto ?

    Essas metricas, Acuracia, Precis√£o e Recall, podem ser obtidas atraves da matriz de confus√£o: from sklearn.metrics import confusion_matrix
    Ou mais diretamente: from sklearn.metrics import precision_score, recall_score

    - F1 Score: media harmonica entre precisao e recall, para ter um valor alto ambos devem ser altos.
        Pode ser obtido por from sklearn.metrics import f1_score
    
    - Curva Precisao VS Recall, utilizada para verificar os thresholds, limiares. √â possivel ver graficamente como eles se influenciam.

‚Ä¢ RandomForestRegressor: regressor usado para melhor aproxima√ß√£o dos dados. Utiliza um conjunto de arvores com parametros aleatorios para fazer as previsoes, 
o resultado final √© a media de cada arvore. Porem √© mais lento, mas evita overfitting.

‚Ä¢ Ao final notou-se uma grande taxa de erros entre alguns numeros, por exemplo alta taxa de erro na decisao de 5 igual a 8. Isso pode se dar
devido a mal escrita dos valores, possivelmente um humano teria dificuldade em entender o numero escrito.

‚Ä¢ Uma tatica para aumentar o dataset √© gerar novas imagens deslocadas alguns pixels, assim temos mais dados para treino e isso pode diminuir os erros.